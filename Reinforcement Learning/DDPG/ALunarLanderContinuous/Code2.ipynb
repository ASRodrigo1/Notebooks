{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ef76775f4c1a>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is GPU available? True\n",
      "TF version: 2.3.1\n",
      "Keras version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Is GPU available?\", tf.test.is_gpu_available())\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Keras version:\", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBuffer():\n",
    "    def __init__(self, maxsize, statedim, naction):\n",
    "        self.cnt = 0\n",
    "        self.maxsize = maxsize\n",
    "        self.state_memory = np.zeros((maxsize, *statedim), dtype=np.float32)\n",
    "        self.action_memory = np.zeros((maxsize, naction), dtype=np.float32)\n",
    "        self.reward_memory = np.zeros((maxsize,), dtype=np.float32)\n",
    "        self.n_state_memory = np.zeros((maxsize, *statedim), dtype=np.float32)\n",
    "        self.done_memory = np.zeros((maxsize,), dtype= np.bool)\n",
    "\n",
    "    def store(self, state, action, reward, n_state, done):\n",
    "        index = self.cnt % self.maxsize\n",
    "        self.state_memory[index] = state\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.n_state_memory[index] = n_state\n",
    "        self.done_memory[index] = 1 - int(done)\n",
    "        self.cnt += 1\n",
    "\n",
    "    def take_data(self, batch_size):\n",
    "        max_mem = min(self.cnt, self.maxsize)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace= False)  \n",
    "        states = self.state_memory[batch]\n",
    "        n_states = self.n_state_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        dones = self.done_memory[batch]\n",
    "        return states, actions, rewards, n_states, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.f1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.f2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.v =  tf.keras.layers.Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputstate, action):\n",
    "        x = self.f1(tf.concat([inputstate, action], axis=1))\n",
    "        x = self.f2(x)\n",
    "        x = self.v(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, no_action):\n",
    "        super(Actor, self).__init__()    \n",
    "        self.f1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.f2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.mu =  tf.keras.layers.Dense(no_action, activation='tanh')\n",
    "\n",
    "    def call(self, state):\n",
    "        x = self.f1(state)\n",
    "        x = self.f2(x)\n",
    "        x = self.mu(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, n_actions, min_action, max_action):\n",
    "        self.actor = Actor(n_actions)\n",
    "        self.critic = Critic()\n",
    "        self.actor_target = Actor(n_actions)\n",
    "        self.critic_target = Critic()\n",
    "        self.batch_size = 64\n",
    "        self.n_actions = n_actions\n",
    "        self.actor_opt = Adam(1e-4)\n",
    "        self.critic_opt = Adam(1e-4)\n",
    "        #self.memory = deque(maxlen=100000)\n",
    "        self.memory = RBuffer(100000, (8, ), 2)\n",
    "        self.steps = 0\n",
    "        self.replace = 5\n",
    "        self.gamma = 0.99\n",
    "        self.min_action = min_action\n",
    "        self.max_action = max_action\n",
    "        self.tau = 0.005\n",
    "        self.actor_target.compile(optimizer=self.actor_opt)\n",
    "        self.critic_target.compile(optimizer=self.critic_opt)\n",
    "    \n",
    "    def store(self, state, action, reward, n_state, done):\n",
    "        pack = [np.expand_dims(state, axis=0), action, reward, np.expand_dims(n_state, axis=0), done]\n",
    "        self.memory.append(pack)\n",
    "    \n",
    "    def take_data(self, batch_size):\n",
    "        pack = random.sample(self.memory, batch_size)\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        n_states = []\n",
    "        dones = []\n",
    "        for i in range(batch_size):\n",
    "            states.append(pack[i][0])\n",
    "            actions.append(pack[i][1])\n",
    "            rewards.append(pack[i][2])\n",
    "            n_states.append(pack[i][3])\n",
    "            dones.append(pack[i][4])\n",
    "        return states, actions, rewards, n_states, dones\n",
    "\n",
    "\n",
    "    def act(self, state, evaluate=False):\n",
    "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
    "        actions = self.actor(state)\n",
    "        if not evaluate:\n",
    "            actions += tf.random.normal(shape=[self.n_actions], mean=0.0, stddev=0.1)\n",
    "\n",
    "        actions = self.max_action * (tf.clip_by_value(actions, self.min_action, self.max_action))\n",
    "        return actions[0]\n",
    "    \n",
    "    def update_target(self, tau=None):\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        weights1 = []\n",
    "        targets1 = self.actor_target.weights\n",
    "        for i, weight in enumerate(self.actor.weights):\n",
    "            weights1.append(weight * tau + targets1[i]*(1-tau))\n",
    "        self.actor_target.set_weights(weights1)\n",
    "\n",
    "        weights2 = []\n",
    "        targets2 = self.critic_target.weights\n",
    "        for i, weight in enumerate(self.critic.weights):\n",
    "            weights2.append(weight * tau + targets2[i]*(1-tau))\n",
    "        self.critic_target.set_weights(weights2)\n",
    "    \n",
    "    def upgrade(self):\n",
    "        if self.memory.cnt < 3*self.batch_size:\n",
    "            return \n",
    "\n",
    "        states, actions, rewards, n_states, dones = self.memory.take_data(self.batch_size)\n",
    "\n",
    "        states = tf.convert_to_tensor(states, dtype= tf.float32)\n",
    "        n_states = tf.convert_to_tensor(n_states, dtype= tf.float32)\n",
    "        rewards = tf.convert_to_tensor(rewards, dtype= tf.float32)\n",
    "        actions = tf.convert_to_tensor(actions, dtype= tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "\n",
    "            target_actions = self.actor_target(n_states)\n",
    "            target_n_state = tf.squeeze(self.critic_target(n_states, target_actions), 1)\n",
    "            critic_value = tf.squeeze(self.critic(states, actions), 1)\n",
    "            target_values = rewards + self.gamma * target_n_state * dones\n",
    "            critic_loss = tf.keras.losses.MSE(target_values, critic_value)\n",
    "\n",
    "            new_policy_actions = self.actor(states)\n",
    "            actor_loss = -self.critic(states, new_policy_actions)\n",
    "            actor_loss = tf.math.reduce_mean(actor_loss)\n",
    "\n",
    "        grads1 = tape1.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        grads2 = tape2.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.actor_opt.apply_gradients(zip(grads1, self.actor.trainable_variables))\n",
    "        self.critic_opt.apply_gradients(zip(grads2, self.critic.trainable_variables))\n",
    "        \n",
    "        self.update_target()\n",
    "\n",
    "        self.steps +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_action: -1.0\n",
      "Max_action:  1.0\n",
      "States:  (8,)\n",
      "Actions:  (2,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "\n",
    "print('Min_action:', env.action_space.low[0])\n",
    "print('Max_action: ', env.action_space.high[0])\n",
    "print('States: ', env.observation_space.shape)\n",
    "print('Actions: ', env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0  Score: -138.63760360875517  AVG: -138\n",
      "Episode: 1  Score: -288.17082639209445  AVG: -213\n",
      "Episode: 2  Score: -228.09432249356544  AVG: -218\n",
      "Episode: 3  Score: -375.364514604419  AVG: -257\n",
      "Episode: 4  Score: -58.42399640938502  AVG: -217\n",
      "Episode: 5  Score: -141.1209525514501  AVG: -204\n",
      "Episode: 6  Score: -105.20447153843132  AVG: -190\n",
      "Episode: 7  Score: -2.8650249938707617  AVG: -167\n",
      "Episode: 8  Score: -108.02753389543975  AVG: -160\n",
      "Episode: 9  Score: -158.59097306323645  AVG: -160\n",
      "Episode: 10  Score: -155.3312360838984  AVG: -159\n",
      "Episode: 11  Score: -80.82933503831245  AVG: -153\n",
      "Episode: 12  Score: -385.90357210461724  AVG: -171\n",
      "Episode: 13  Score: -68.73067687453185  AVG: -163\n",
      "Episode: 14  Score: -157.9831665500176  AVG: -163\n",
      "Episode: 15  Score: -83.67759341353931  AVG: -158\n",
      "Episode: 16  Score: -141.91993261485385  AVG: -157\n",
      "Episode: 17  Score: -38.897231486078134  AVG: -150\n",
      "Episode: 18  Score: -131.84624462699387  AVG: -149\n",
      "Episode: 19  Score: -122.75608943606636  AVG: -148\n",
      "Episode: 20  Score: -124.61171395102258  AVG: -147\n",
      "Episode: 21  Score: -165.39462036357978  AVG: -148\n",
      "Episode: 22  Score: -167.81755463777347  AVG: -149\n",
      "Episode: 23  Score: -263.59434153790426  AVG: -153\n",
      "Episode: 24  Score: -99.68262355067284  AVG: -151\n",
      "Episode: 25  Score: -17.10771607844552  AVG: -146\n",
      "Episode: 26  Score: -324.6354582603252  AVG: -153\n",
      "Episode: 27  Score: -142.37932204938352  AVG: -152\n",
      "Episode: 28  Score: -99.11581956179609  AVG: -150\n",
      "Episode: 29  Score: -255.79913191855886  AVG: -154\n",
      "Episode: 30  Score: 28.56559930107545  AVG: -148\n",
      "Episode: 31  Score: -106.87495515817403  AVG: -147\n",
      "Episode: 32  Score: -128.11338077090127  AVG: -146\n",
      "Episode: 33  Score: -201.778866938835  AVG: -148\n",
      "Episode: 34  Score: -138.09338711614407  AVG: -147\n",
      "Episode: 35  Score: -199.65093563008892  AVG: -149\n",
      "Episode: 36  Score: -186.41393373869425  AVG: -150\n",
      "Episode: 37  Score: -97.33846715672688  AVG: -149\n",
      "Episode: 38  Score: -222.79371811191152  AVG: -150\n",
      "Episode: 39  Score: -117.91190825772307  AVG: -150\n",
      "Episode: 40  Score: -184.4024982121702  AVG: -150\n",
      "Episode: 41  Score: -217.85565059474771  AVG: -152\n",
      "Episode: 42  Score: -208.15477213435273  AVG: -153\n",
      "Episode: 43  Score: -99.284337771951  AVG: -152\n",
      "Episode: 44  Score: -364.1785365923181  AVG: -157\n",
      "Episode: 45  Score: -378.7416694702436  AVG: -162\n",
      "Episode: 46  Score: -278.61341096865596  AVG: -164\n",
      "Episode: 47  Score: -407.40611124622023  AVG: -169\n",
      "Episode: 48  Score: -30.429823510229127  AVG: -166\n",
      "Episode: 49  Score: -346.8172059726746  AVG: -170\n",
      "Episode: 50  Score: -52.71877916616215  AVG: -168\n",
      "Episode: 51  Score: -320.8490136124931  AVG: -171\n",
      "Episode: 52  Score: -152.40698247698623  AVG: -170\n",
      "Episode: 53  Score: -357.4069053580211  AVG: -174\n",
      "Episode: 54  Score: -159.78267534708854  AVG: -173\n",
      "Episode: 55  Score: -300.1177633094346  AVG: -176\n",
      "Episode: 56  Score: -55.494266578089686  AVG: -173\n",
      "Episode: 57  Score: -86.77279075398222  AVG: -172\n",
      "Episode: 58  Score: -203.22926041671343  AVG: -173\n",
      "Episode: 59  Score: -116.12170114416926  AVG: -172\n",
      "Episode: 60  Score: -67.1755739177616  AVG: -170\n",
      "Episode: 61  Score: -114.73089107259932  AVG: -169\n",
      "Episode: 62  Score: -51.691415942007076  AVG: -167\n",
      "Episode: 63  Score: -43.868401837893245  AVG: -165\n",
      "Episode: 64  Score: -348.7409592993296  AVG: -168\n",
      "Episode: 65  Score: -222.9684532133017  AVG: -169\n",
      "Episode: 66  Score: -100.05768806664761  AVG: -168\n",
      "Episode: 67  Score: -62.781691431876155  AVG: -166\n",
      "Episode: 68  Score: -154.3726486526242  AVG: -166\n",
      "Episode: 69  Score: -239.63725650152486  AVG: -167\n",
      "Episode: 70  Score: -200.20350457352552  AVG: -168\n",
      "Episode: 71  Score: -87.65887531400172  AVG: -166\n",
      "Episode: 72  Score: -307.4614707272691  AVG: -168\n",
      "Episode: 73  Score: -92.12161549391493  AVG: -167\n",
      "Episode: 74  Score: 137.37176079066674  AVG: -163\n",
      "Episode: 75  Score: -31.740858805019826  AVG: -161\n",
      "Episode: 76  Score: -276.6602451857028  AVG: -163\n",
      "Episode: 77  Score: -126.86032607615687  AVG: -163\n",
      "Episode: 78  Score: -101.53915618761876  AVG: -162\n",
      "Episode: 79  Score: -83.40025278194362  AVG: -161\n",
      "Episode: 80  Score: -71.71232049127198  AVG: -160\n",
      "Episode: 81  Score: -255.25148397332435  AVG: -161\n",
      "Episode: 82  Score: -239.51463724389515  AVG: -162\n",
      "Episode: 83  Score: -230.1166071373597  AVG: -163\n",
      "Episode: 84  Score: -63.87566920604796  AVG: -161\n",
      "Episode: 85  Score: -231.29024124290936  AVG: -162\n",
      "Episode: 86  Score: -20.09320539797551  AVG: -161\n",
      "Episode: 87  Score: -278.8529505537049  AVG: -162\n",
      "Episode: 88  Score: -60.76166952492031  AVG: -161\n",
      "Episode: 89  Score: -94.48234253654729  AVG: -160\n",
      "Episode: 90  Score: -85.0536887936246  AVG: -159\n",
      "Episode: 91  Score: 15.257218523321882  AVG: -157\n",
      "Episode: 92  Score: -3.39454307909881  AVG: -156\n",
      "Episode: 93  Score: -99.49510842802407  AVG: -155\n",
      "Episode: 94  Score: -67.76917761126518  AVG: -154\n",
      "Episode: 95  Score: -8.123527764791248  AVG: -153\n",
      "Episode: 96  Score: -84.46795375198005  AVG: -152\n",
      "Episode: 97  Score: -11.761278119720316  AVG: -150\n",
      "Episode: 98  Score: -95.97316636950251  AVG: -150\n",
      "Episode: 99  Score: -15.910764741917731  AVG: -149\n",
      "Episode: 100  Score: 90.39071060687561  AVG: -146\n",
      "Episode: 101  Score: -71.47427991656873  AVG: -144\n",
      "Episode: 102  Score: -89.03301540297412  AVG: -143\n",
      "Episode: 103  Score: -65.50123485800651  AVG: -140\n",
      "Episode: 104  Score: -42.65005629186782  AVG: -139\n",
      "Episode: 105  Score: -84.51703057063864  AVG: -139\n",
      "Episode: 106  Score: -126.15648518676156  AVG: -139\n",
      "Episode: 107  Score: -111.81312238692475  AVG: -140\n",
      "Episode: 108  Score: -21.094481241897796  AVG: -139\n",
      "Episode: 109  Score: -44.09811932210962  AVG: -138\n",
      "Episode: 110  Score: -130.601159094061  AVG: -138\n",
      "Episode: 111  Score: -153.89418627125167  AVG: -139\n",
      "Episode: 112  Score: -128.03195628770953  AVG: -136\n",
      "Episode: 113  Score: -37.37841933354419  AVG: -136\n",
      "Episode: 114  Score: -141.75702299255082  AVG: -136\n",
      "Episode: 115  Score: -23.162906034024004  AVG: -135\n",
      "Episode: 116  Score: -135.39830393983863  AVG: -135\n",
      "Episode: 117  Score: -103.8403629166966  AVG: -136\n",
      "Episode: 118  Score: -139.98096609194442  AVG: -136\n",
      "Episode: 119  Score: -90.87838350142326  AVG: -135\n",
      "Episode: 120  Score: -144.27892757343346  AVG: -136\n",
      "Episode: 121  Score: -85.80332129251111  AVG: -135\n",
      "Episode: 122  Score: -218.85517975147735  AVG: -135\n",
      "Episode: 123  Score: -288.1110753345416  AVG: -135\n",
      "Episode: 124  Score: -0.9982259430550613  AVG: -134\n",
      "Episode: 125  Score: -226.5219893706539  AVG: -137\n",
      "Episode: 126  Score: -170.42100036690897  AVG: -135\n",
      "Episode: 127  Score: -350.2129014553608  AVG: -137\n",
      "Episode: 128  Score: -42.20409949723066  AVG: -137\n",
      "Episode: 129  Score: -277.06858572260836  AVG: -137\n",
      "Episode: 130  Score: -197.3547382859867  AVG: -139\n",
      "Episode: 131  Score: -73.20021856937647  AVG: -139\n",
      "Episode: 132  Score: -127.46744876827714  AVG: -139\n",
      "Episode: 133  Score: -39.51076174527878  AVG: -137\n",
      "Episode: 134  Score: -101.68948188151657  AVG: -137\n",
      "Episode: 135  Score: -65.29417716782513  AVG: -135\n",
      "Episode: 136  Score: -94.98741493142442  AVG: -134\n",
      "Episode: 137  Score: -473.9534919666888  AVG: -138\n",
      "Episode: 138  Score: -335.1228916648443  AVG: -139\n",
      "Episode: 139  Score: -261.990340022108  AVG: -141\n",
      "Episode: 140  Score: -400.3526858957129  AVG: -143\n",
      "Episode: 141  Score: -64.75746542041648  AVG: -141\n",
      "Episode: 142  Score: -259.6255351463997  AVG: -142\n",
      "Episode: 143  Score: -226.5521620288103  AVG: -143\n",
      "Episode: 144  Score: -110.13411325666898  AVG: -141\n",
      "Episode: 145  Score: -357.91391696397733  AVG: -140\n",
      "Episode: 146  Score: -1.470222521133607  AVG: -138\n",
      "Episode: 147  Score: -52.39262182168293  AVG: -134\n",
      "Episode: 148  Score: -269.36967962735093  AVG: -136\n",
      "Episode: 149  Score: -50.57922029478975  AVG: -134\n",
      "Episode: 150  Score: -26.420260397606583  AVG: -133\n",
      "Episode: 151  Score: -53.4087218664494  AVG: -131\n",
      "Episode: 152  Score: -67.19548262966524  AVG: -130\n",
      "Episode: 153  Score: -330.651610816917  AVG: -129\n",
      "Episode: 154  Score: -198.68509406690907  AVG: -130\n",
      "Episode: 155  Score: -50.884334113825034  AVG: -127\n",
      "Episode: 156  Score: -182.7545836694795  AVG: -129\n",
      "Episode: 157  Score: -213.92672890659833  AVG: -130\n",
      "Episode: 158  Score: -202.06375784461218  AVG: -130\n",
      "Episode: 159  Score: -85.90093030793223  AVG: -130\n",
      "Episode: 160  Score: -206.06716057537886  AVG: -131\n",
      "Episode: 161  Score: -296.79753991054133  AVG: -133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 162  Score: -112.87316116661988  AVG: -133\n",
      "Episode: 163  Score: -299.35387341284945  AVG: -136\n",
      "Episode: 164  Score: -228.6825297549192  AVG: -135\n",
      "Episode: 165  Score: -329.0485131573962  AVG: -136\n",
      "Episode: 166  Score: -136.85552041417094  AVG: -136\n",
      "Episode: 167  Score: -60.65636095892091  AVG: -136\n",
      "Episode: 168  Score: -280.76564855816895  AVG: -137\n",
      "Episode: 169  Score: -207.2939736979362  AVG: -137\n",
      "Episode: 170  Score: -183.83913707722235  AVG: -137\n",
      "Episode: 171  Score: -269.0507839479559  AVG: -139\n",
      "Episode: 172  Score: -358.24307169536047  AVG: -139\n",
      "Episode: 173  Score: -375.5765484425669  AVG: -142\n",
      "Episode: 174  Score: -173.76507184751978  AVG: -145\n",
      "Episode: 175  Score: -115.35800501612049  AVG: -146\n",
      "Episode: 176  Score: -161.85592171073202  AVG: -145\n",
      "Episode: 177  Score: -352.48952151544745  AVG: -147\n",
      "Episode: 178  Score: -298.21266008367525  AVG: -149\n",
      "Episode: 179  Score: -197.60221001678286  AVG: -150\n",
      "Episode: 180  Score: -227.08736081593094  AVG: -152\n",
      "Episode: 181  Score: -389.82852785817835  AVG: -153\n",
      "Episode: 182  Score: 6.018279031577862  AVG: -151\n",
      "Episode: 183  Score: -238.04216804174843  AVG: -151\n",
      "Episode: 184  Score: -252.53752611205323  AVG: -153\n",
      "Episode: 185  Score: -42.166851213964854  AVG: -151\n",
      "Episode: 186  Score: -25.870166016131193  AVG: -151\n",
      "Episode: 187  Score: -215.40197982210407  AVG: -150\n",
      "Episode: 188  Score: -242.74811921613494  AVG: -152\n",
      "Episode: 189  Score: -58.98575903870056  AVG: -152\n",
      "Episode: 190  Score: -41.771374791927414  AVG: -151\n",
      "Episode: 191  Score: -7.118757843918559  AVG: -151\n",
      "Episode: 192  Score: -199.29962141142755  AVG: -153\n",
      "Episode: 193  Score: -84.2975463367879  AVG: -153\n",
      "Episode: 194  Score: -7.616785066183894  AVG: -153\n",
      "Episode: 195  Score: -214.3012764333091  AVG: -155\n",
      "Episode: 196  Score: -257.4322521180907  AVG: -156\n",
      "Episode: 197  Score: -175.83913435281636  AVG: -158\n",
      "Episode: 198  Score: -18.806572301561317  AVG: -157\n",
      "Episode: 199  Score: -349.62340592776553  AVG: -161\n",
      "Episode: 200  Score: -100.44924415654083  AVG: -163\n",
      "Episode: 201  Score: -200.6150645007523  AVG: -164\n",
      "Episode: 202  Score: -4.239270923795985  AVG: -163\n",
      "Episode: 203  Score: -322.86557156957076  AVG: -166\n",
      "Episode: 204  Score: 3.8220613221230195  AVG: -165\n",
      "Episode: 205  Score: -126.41231672973764  AVG: -166\n",
      "Episode: 206  Score: -31.766626871922284  AVG: -165\n",
      "Episode: 207  Score: -5.124073554625895  AVG: -164\n",
      "Episode: 208  Score: -184.21603251620124  AVG: -165\n",
      "Episode: 209  Score: -277.13079498054293  AVG: -168\n",
      "Episode: 210  Score: -78.00200247335499  AVG: -167\n",
      "Episode: 211  Score: -284.37219959416245  AVG: -168\n",
      "Episode: 212  Score: 25.948700949929233  AVG: -167\n",
      "Episode: 213  Score: -96.67870189585693  AVG: -167\n",
      "Episode: 214  Score: -29.389095856912405  AVG: -166\n",
      "Episode: 215  Score: -349.2819296086019  AVG: -169\n",
      "Episode: 216  Score: -75.77014209325853  AVG: -169\n",
      "Episode: 217  Score: -105.0237214917327  AVG: -169\n",
      "Episode: 218  Score: -57.063700812304525  AVG: -168\n",
      "Episode: 219  Score: -173.35740524433646  AVG: -169\n",
      "Episode: 220  Score: -125.15009423532416  AVG: -169\n",
      "Episode: 221  Score: -44.245331823735825  AVG: -168\n",
      "Episode: 222  Score: -266.2558860130122  AVG: -169\n",
      "Episode: 223  Score: -156.33147676332953  AVG: -167\n",
      "Episode: 224  Score: -114.41183332947858  AVG: -169\n",
      "Episode: 225  Score: -242.7106522530661  AVG: -169\n",
      "Episode: 226  Score: -364.005894219016  AVG: -171\n",
      "Episode: 227  Score: -221.40326450508707  AVG: -169\n",
      "Episode: 228  Score: -177.47800822324842  AVG: -171\n",
      "Episode: 229  Score: -124.3742127682545  AVG: -169\n",
      "Episode: 230  Score: -210.05401252480945  AVG: -169\n",
      "Episode: 231  Score: -350.293367082916  AVG: -172\n",
      "Episode: 232  Score: -205.86082091495808  AVG: -173\n",
      "Episode: 233  Score: -76.16205816519751  AVG: -173\n",
      "Episode: 234  Score: -90.42864094324912  AVG: -173\n",
      "Episode: 235  Score: -192.2271610276431  AVG: -174\n",
      "Episode: 236  Score: -217.2972996745355  AVG: -176\n",
      "Episode: 237  Score: -252.75035555890906  AVG: -173\n",
      "Episode: 238  Score: -55.250233355747106  AVG: -171\n",
      "Episode: 239  Score: -214.47142596663858  AVG: -170\n",
      "Episode: 240  Score: -250.85428749311723  AVG: -169\n",
      "Episode: 241  Score: -180.33158855687327  AVG: -170\n",
      "Episode: 242  Score: -258.02367933360523  AVG: -170\n",
      "Episode: 243  Score: -59.79426476029003  AVG: -168\n",
      "Episode: 244  Score: -257.0541621267978  AVG: -170\n",
      "Episode: 245  Score: -298.5827695915349  AVG: -169\n",
      "Episode: 246  Score: -245.33112773176694  AVG: -171\n",
      "Episode: 247  Score: -164.53483626916793  AVG: -173\n",
      "Episode: 248  Score: -117.78478611075843  AVG: -171\n",
      "Episode: 249  Score: -153.77661242730267  AVG: -172\n",
      "Episode: 250  Score: -138.1143188887633  AVG: -173\n",
      "Episode: 251  Score: -100.9393252690698  AVG: -174\n",
      "Episode: 252  Score: -106.44914279506388  AVG: -174\n",
      "Episode: 253  Score: -157.51258827292193  AVG: -172\n",
      "Episode: 254  Score: -175.8641858421331  AVG: -172\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(2, -1, 1)\n",
    "\n",
    "n_episodes = 2000\n",
    "avg_hist = []\n",
    "scores = []\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    score = 0 \n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        n_state, reward, done, _ = env.step(action)\n",
    "        agent.memory.store(state, action, reward, n_state, done)\n",
    "        agent.upgrade()\n",
    "        state = n_state\n",
    "        score += reward\n",
    "    \n",
    "    scores.append(score)\n",
    "    avg_reward = int(np.mean(scores[-100:]))\n",
    "    avg_hist.append(avg_reward)\n",
    "    print(f'Episode: {i}  Score: {score}  AVG: {avg_reward}')\n",
    "    \n",
    "    if avg_reward >= 200:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_hist)\n",
    "plt.grid()\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Avg rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state, True)\n",
    "        n_state, _, done, _ = env.step(action)\n",
    "        state = n_state\n",
    "        env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
