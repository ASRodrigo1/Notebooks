{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2 1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "problem = 'LunarLanderContinuous-v2'\n",
    "#problem = 'Pendulum-v0'\n",
    "env = gym.make(problem)\n",
    "\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(num_states, num_actions, upper_bound, lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This shit just doesn't work with deque\n",
    "### So it needs to be this way\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "    \n",
    "    @tf.function\n",
    "    def update(self, states, actions, rewards, n_states):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(n_states, training=True)\n",
    "            y = rewards + gamma * target_critic([n_states, target_actions], training=True)\n",
    "            critic_value = critic_model([states, actions], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(zip(critic_grad, critic_model.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            acts = actor_model(states, training=True)\n",
    "            critic_value = critic_model([states, acts], training=True)\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(zip(actor_grad, actor_model.trainable_variables))\n",
    "        \n",
    "    def learn(self):\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor():\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(256, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(2, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def critic():\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(256, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(256, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, noise_obj):\n",
    "    state = tf.expand_dims(state, 0)\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_obj()\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "actor_model = actor()\n",
    "critic_model = critic()\n",
    "\n",
    "target_actor = actor()\n",
    "target_critic = critic()\n",
    "\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "critic_lr = 0.0005\n",
    "actor_lr = 0.0005\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 2000\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "tau = 0.005\n",
    "\n",
    "memory = Buffer(50000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Avg score -450.6093964189201\n",
      "Episode 1 Avg score -398.2833827378147\n",
      "Episode 2 Avg score -507.59979983803777\n",
      "Episode 3 Avg score -562.2027921499589\n",
      "Episode 4 Avg score -569.624299392421\n",
      "Episode 5 Avg score -586.7020341994127\n",
      "Episode 6 Avg score -624.9890687880983\n",
      "Episode 7 Avg score -643.0601275223013\n",
      "Episode 8 Avg score -647.7114793869096\n",
      "Episode 9 Avg score -644.667887296718\n",
      "Episode 10 Avg score -655.5862183105421\n",
      "Episode 11 Avg score -658.5156396861669\n",
      "Episode 12 Avg score -668.7519162162496\n",
      "Episode 13 Avg score -664.3272525351882\n",
      "Episode 14 Avg score -627.1765433966134\n",
      "Episode 15 Avg score -596.683019651146\n",
      "Episode 16 Avg score -574.6843872689534\n",
      "Episode 17 Avg score -551.622145143026\n",
      "Episode 18 Avg score -529.6344502987391\n",
      "Episode 19 Avg score -509.7768479413332\n",
      "Episode 20 Avg score -492.2695289456448\n",
      "Episode 21 Avg score -477.1609040225799\n",
      "Episode 22 Avg score -461.0867557130995\n",
      "Episode 23 Avg score -446.5700503501494\n",
      "Episode 24 Avg score -439.87085854448776\n",
      "Episode 25 Avg score -429.64906195047104\n",
      "Episode 26 Avg score -417.2132749311112\n",
      "Episode 27 Avg score -411.4525385783322\n",
      "Episode 28 Avg score -412.63368021231383\n",
      "Episode 29 Avg score -416.7988038783013\n",
      "Episode 30 Avg score -419.4847948829029\n",
      "Episode 31 Avg score -421.59619102527984\n",
      "Episode 32 Avg score -418.4147272672954\n",
      "Episode 33 Avg score -414.1422133565066\n",
      "Episode 34 Avg score -409.4762264656918\n",
      "Episode 35 Avg score -406.10558136626736\n",
      "Episode 36 Avg score -403.06936776480376\n",
      "Episode 37 Avg score -402.54950343143526\n",
      "Episode 38 Avg score -398.34300958405856\n",
      "Episode 39 Avg score -397.32534886218156\n",
      "Episode 40 Avg score -393.6587493553046\n",
      "Episode 41 Avg score -392.99647843514856\n",
      "Episode 42 Avg score -378.5526117735881\n",
      "Episode 43 Avg score -361.4401546602735\n",
      "Episode 44 Avg score -353.79472119404943\n",
      "Episode 45 Avg score -347.8672013557701\n",
      "Episode 46 Avg score -333.35540902766746\n",
      "Episode 47 Avg score -318.4240493474428\n",
      "Episode 48 Avg score -303.10229757858144\n",
      "Episode 49 Avg score -290.00379119446944\n",
      "Episode 50 Avg score -273.12952150739295\n",
      "Episode 51 Avg score -259.00875974844496\n",
      "Episode 52 Avg score -242.57566477773162\n",
      "Episode 53 Avg score -227.27459999040403\n",
      "Episode 54 Avg score -228.14742012065508\n",
      "Episode 55 Avg score -227.27203626893842\n",
      "Episode 56 Avg score -225.32426412241438\n",
      "Episode 57 Avg score -223.78778123954135\n",
      "Episode 58 Avg score -223.83888021744588\n",
      "Episode 59 Avg score -223.1603028575998\n",
      "Episode 60 Avg score -221.93739415025098\n",
      "Episode 61 Avg score -221.28058505107356\n",
      "Episode 62 Avg score -222.39457446906482\n",
      "Episode 63 Avg score -221.97046304401874\n",
      "Episode 64 Avg score -216.74334409678644\n",
      "Episode 65 Avg score -216.3382997061539\n",
      "Episode 66 Avg score -216.93161484647848\n",
      "Episode 67 Avg score -213.1913679373083\n",
      "Episode 68 Avg score -204.80883372750765\n",
      "Episode 69 Avg score -190.69079946384414\n",
      "Episode 70 Avg score -185.57121216851226\n",
      "Episode 71 Avg score -181.55421950887148\n",
      "Episode 72 Avg score -178.03347516254652\n",
      "Episode 73 Avg score -174.11971192076484\n",
      "Episode 74 Avg score -171.31803021562285\n",
      "Episode 75 Avg score -167.81655704646272\n",
      "Episode 76 Avg score -161.81290565152287\n",
      "Episode 77 Avg score -151.48322950136392\n",
      "Episode 78 Avg score -149.8290321659278\n",
      "Episode 79 Avg score -145.35305448317575\n",
      "Episode 80 Avg score -138.22300525353597\n",
      "Episode 81 Avg score -135.6837855986875\n",
      "Episode 82 Avg score -136.81662497884773\n",
      "Episode 83 Avg score -141.09085307794572\n",
      "Episode 84 Avg score -138.7126812687722\n",
      "Episode 85 Avg score -134.3548499880123\n",
      "Episode 86 Avg score -131.52493334792774\n",
      "Episode 87 Avg score -130.95216891159436\n",
      "Episode 88 Avg score -131.96542833064888\n",
      "Episode 89 Avg score -132.95434308270916\n",
      "Episode 90 Avg score -136.1203711613148\n",
      "Episode 91 Avg score -139.56300709634928\n",
      "Episode 92 Avg score -141.53865078395884\n",
      "Episode 93 Avg score -151.10620735934947\n",
      "Episode 94 Avg score -156.1722323884092\n",
      "Episode 95 Avg score -159.8906444713633\n",
      "Episode 96 Avg score -163.8964204237372\n",
      "Episode 97 Avg score -169.67105069641116\n",
      "Episode 98 Avg score -174.88668080900987\n",
      "Episode 99 Avg score -179.84357734142287\n",
      "Episode 100 Avg score -186.32771772788206\n",
      "Episode 101 Avg score -191.43562037383987\n",
      "Episode 102 Avg score -195.06236705499802\n",
      "Episode 103 Avg score -201.29259007606896\n",
      "Episode 104 Avg score -203.51409381994947\n",
      "Episode 105 Avg score -204.7379752909255\n",
      "Episode 106 Avg score -208.70041754490134\n",
      "Episode 107 Avg score -213.1711340630871\n",
      "Episode 108 Avg score -220.73305890387937\n",
      "Episode 109 Avg score -235.48326407359878\n",
      "Episode 110 Avg score -238.3543422041559\n",
      "Episode 111 Avg score -240.6649364510171\n",
      "Episode 112 Avg score -248.91818194891047\n",
      "Episode 113 Avg score -256.6428918443033\n",
      "Episode 114 Avg score -261.51312718403767\n",
      "Episode 115 Avg score -266.28103771005027\n",
      "Episode 116 Avg score -270.620986919416\n",
      "Episode 117 Avg score -273.65473056976737\n",
      "Episode 118 Avg score -272.2964647773266\n",
      "Episode 119 Avg score -274.6774219931304\n",
      "Episode 120 Avg score -279.470542540099\n",
      "Episode 121 Avg score -276.44251935920386\n",
      "Episode 122 Avg score -275.098956619624\n",
      "Episode 123 Avg score -273.7318191714683\n",
      "Episode 124 Avg score -273.3676241101175\n",
      "Episode 125 Avg score -271.921282302823\n",
      "Episode 126 Avg score -272.697731116406\n",
      "Episode 127 Avg score -271.2091089274993\n",
      "Episode 128 Avg score -271.85129685801104\n",
      "Episode 129 Avg score -272.3034687064111\n",
      "Episode 130 Avg score -270.09418238983073\n",
      "Episode 131 Avg score -267.34175463392455\n",
      "Episode 132 Avg score -265.1644738563371\n",
      "Episode 133 Avg score -258.63043150878264\n",
      "Episode 134 Avg score -253.24772106650045\n",
      "Episode 135 Avg score -251.43853661010044\n",
      "Episode 136 Avg score -246.82725803083645\n",
      "Episode 137 Avg score -245.95970504826474\n",
      "Episode 138 Avg score -244.24206619424405\n",
      "Episode 139 Avg score -242.49267699226942\n",
      "Episode 140 Avg score -243.99571796140964\n",
      "Episode 141 Avg score -238.94244886303278\n",
      "Episode 142 Avg score -234.19499529988667\n",
      "Episode 143 Avg score -228.2419658471571\n",
      "Episode 144 Avg score -227.7126246771085\n",
      "Episode 145 Avg score -226.94444480731994\n",
      "Episode 146 Avg score -226.06086425997515\n",
      "Episode 147 Avg score -227.90182336159842\n",
      "Episode 148 Avg score -225.04192488532817\n",
      "Episode 149 Avg score -214.59857284354194\n",
      "Episode 150 Avg score -210.58313258198945\n",
      "Episode 151 Avg score -208.13064160314352\n",
      "Episode 152 Avg score -200.46671329531426\n",
      "Episode 153 Avg score -196.05112440021944\n",
      "Episode 154 Avg score -193.67431905281325\n",
      "Episode 155 Avg score -193.4682745002834\n",
      "Episode 156 Avg score -197.17309407128394\n",
      "Episode 157 Avg score -206.84441516729376\n",
      "Episode 158 Avg score -218.9622594169563\n",
      "Episode 159 Avg score -224.6459301457703\n",
      "Episode 160 Avg score -237.39330923520976\n",
      "Episode 161 Avg score -252.40755824041986\n",
      "Episode 162 Avg score -260.4831743575718\n",
      "Episode 163 Avg score -268.4845323695628\n",
      "Episode 164 Avg score -277.11824812995053\n",
      "Episode 165 Avg score -283.40857983156917\n",
      "Episode 166 Avg score -290.02999279108224\n",
      "Episode 167 Avg score -295.71216659056915\n",
      "Episode 168 Avg score -307.085251630697\n",
      "Episode 169 Avg score -307.9664639317937\n",
      "Episode 170 Avg score -308.7014021487891\n",
      "Episode 171 Avg score -307.87241123171225\n",
      "Episode 172 Avg score -319.5402661140334\n",
      "Episode 173 Avg score -328.1901999727037\n",
      "Episode 174 Avg score -328.4962813377573\n",
      "Episode 175 Avg score -323.44152757670724\n",
      "Episode 176 Avg score -324.3740325060086\n",
      "Episode 177 Avg score -326.7378852585406\n",
      "Episode 178 Avg score -331.41356725239\n",
      "Episode 179 Avg score -336.832667340268\n",
      "Episode 180 Avg score -336.57968493794675\n",
      "Episode 181 Avg score -343.4469821888111\n",
      "Episode 182 Avg score -346.33605027359533\n",
      "Episode 183 Avg score -352.09667813411227\n",
      "Episode 184 Avg score -358.73417952803413\n",
      "Episode 185 Avg score -360.9477039181993\n",
      "Episode 186 Avg score -367.7280299621456\n",
      "Episode 187 Avg score -365.11185296832355\n",
      "Episode 188 Avg score -362.12756165727836\n",
      "Episode 189 Avg score -362.6378987276036\n",
      "Episode 190 Avg score -360.98015055409047\n",
      "Episode 191 Avg score -357.93446099160866\n",
      "Episode 192 Avg score -358.471750781463\n",
      "Episode 193 Avg score -357.35713229625287\n",
      "Episode 194 Avg score -355.5133911616811\n",
      "Episode 195 Avg score -358.3513719239802\n",
      "Episode 196 Avg score -360.1521673023266\n",
      "Episode 197 Avg score -357.7745012137268\n",
      "Episode 198 Avg score -349.44134738052963\n",
      "Episode 199 Avg score -340.7030789928574\n",
      "Episode 200 Avg score -326.24896745596226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 201 Avg score -314.99959028859877\n",
      "Episode 202 Avg score -308.51946348914447\n",
      "Episode 203 Avg score -302.4559799994255\n",
      "Episode 204 Avg score -292.6246484399209\n",
      "Episode 205 Avg score -281.6724068218388\n",
      "Episode 206 Avg score -275.3840854054074\n",
      "Episode 207 Avg score -272.0502689624243\n",
      "Episode 208 Avg score -261.1123994650237\n",
      "Episode 209 Avg score -259.8560510077425\n",
      "Episode 210 Avg score -259.27623191204094\n",
      "Episode 211 Avg score -259.4944045626271\n",
      "Episode 212 Avg score -244.3705581995167\n",
      "Episode 213 Avg score -236.40312512696147\n",
      "Episode 214 Avg score -237.18001002137538\n",
      "Episode 215 Avg score -242.27250788115862\n",
      "Episode 216 Avg score -239.7942524872762\n",
      "Episode 217 Avg score -234.67237759406308\n",
      "Episode 218 Avg score -227.57832860996808\n",
      "Episode 219 Avg score -222.4436247573452\n",
      "Episode 220 Avg score -215.08396207038976\n",
      "Episode 221 Avg score -208.2982022445098\n",
      "Episode 222 Avg score -208.0415922102815\n",
      "Episode 223 Avg score -204.76948858024053\n",
      "Episode 224 Avg score -198.97930313767844\n",
      "Episode 225 Avg score -199.01365922840426\n",
      "Episode 226 Avg score -197.88787157875203\n",
      "Episode 227 Avg score -195.88300269441555\n",
      "Episode 228 Avg score -196.21238722353715\n",
      "Episode 229 Avg score -195.59499043528595\n",
      "Episode 230 Avg score -193.76371651009103\n",
      "Episode 231 Avg score -189.70294639281263\n",
      "Episode 232 Avg score -187.4584269963552\n",
      "Episode 233 Avg score -184.73316013896175\n",
      "Episode 234 Avg score -184.483118599032\n",
      "Episode 235 Avg score -174.7418297049858\n",
      "Episode 236 Avg score -166.4973154445969\n",
      "Episode 237 Avg score -159.98572955630507\n",
      "Episode 238 Avg score -154.83057589736424\n",
      "Episode 239 Avg score -154.61023959144728\n",
      "Episode 240 Avg score -154.009899867785\n",
      "Episode 241 Avg score -149.90213111580692\n",
      "Episode 242 Avg score -149.19312615245326\n",
      "Episode 243 Avg score -147.41562020072598\n",
      "Episode 244 Avg score -148.52982470178796\n",
      "Episode 245 Avg score -151.2319980577942\n",
      "Episode 246 Avg score -147.95106483503378\n",
      "Episode 247 Avg score -146.27004221114294\n",
      "Episode 248 Avg score -144.3076810819774\n",
      "Episode 249 Avg score -145.9658128454766\n",
      "Episode 250 Avg score -146.38719552077094\n",
      "Episode 251 Avg score -147.07555199773344\n",
      "Episode 252 Avg score -152.10378729852542\n",
      "Episode 253 Avg score -149.8093195681519\n",
      "Episode 254 Avg score -149.6282551981852\n",
      "Episode 255 Avg score -149.91032919474702\n",
      "Episode 256 Avg score -150.73497611905327\n",
      "Episode 257 Avg score -154.6442429480387\n",
      "Episode 258 Avg score -157.38627537301585\n",
      "Episode 259 Avg score -155.56594266928943\n",
      "Episode 260 Avg score -155.17179758658554\n",
      "Episode 261 Avg score -154.13593690564093\n",
      "Episode 262 Avg score -151.31004640018008\n",
      "Episode 263 Avg score -147.38686740437691\n",
      "Episode 264 Avg score -143.88791013270801\n",
      "Episode 265 Avg score -141.27072619642541\n",
      "Episode 266 Avg score -136.14757633450716\n",
      "Episode 267 Avg score -138.68772957930915\n",
      "Episode 268 Avg score -136.393958926959\n",
      "Episode 269 Avg score -136.5270758747732\n",
      "Episode 270 Avg score -138.15182988917735\n",
      "Episode 271 Avg score -140.99478389944267\n",
      "Episode 272 Avg score -144.8847195195536\n"
     ]
    }
   ],
   "source": [
    "score_hist = []\n",
    "avg_hist = []\n",
    "\n",
    "for i in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        state = tf.convert_to_tensor(state)\n",
    "        \n",
    "        action = choose_action(state, ou_noise)[0]\n",
    "        \n",
    "        n_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        memory.record((state, action, reward, n_state))\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "        memory.learn()\n",
    "        \n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        state = n_state\n",
    "    \n",
    "    score_hist.append(score)\n",
    "    \n",
    "    avg = np.mean(score_hist[-40:])\n",
    "    \n",
    "    print('Episode', i, 'Avg score', avg)\n",
    "    avg_hist.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_hist)\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
